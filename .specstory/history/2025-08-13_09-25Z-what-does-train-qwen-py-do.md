<!-- Generated by SpecStory -->

# What does train_qwen.py do? (2025-08-13 09:25Z)

_**User**_

@train_qwen.py μ΄κ² μ–΄λ–¤ μ½”λ“μΈμ§€ μ•λ ¤μ¤.

---

_**Assistant**_

μ²¨λ¶€λ `train_qwen.py` νμΌμ„ λ¶„μ„ν•΄λ³΄κ² μµλ‹λ‹¤.


---

Read file: qwen-tuning/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py

---

μ΄ `train_qwen.py` νμΌμ€ **Qwen2.5-VL λ° Qwen2-VL λ©€ν‹°λ¨λ‹¬ λ¨λΈμ νμΈνλ‹μ„ μ„ν• ν›λ ¨ μ¤ν¬λ¦½νΈ**μ…λ‹λ‹¤. μ£Όμ” νΉμ§•λ“¤μ„ μ„¤λ…λ“λ¦¬κ² μµλ‹λ‹¤:

## π― **μ£Όμ” κΈ°λ¥**

### 1. **λ¨λΈ μ§€μ›**
- **Qwen2.5-VL**: μµμ‹  λ²„μ „μ λ©€ν‹°λ¨λ‹¬ λ¨λΈ
- **Qwen2-VL**: μ΄μ „ λ²„μ „μ λ©€ν‹°λ¨λ‹¬ λ¨λΈ
- μ΄λ―Έμ§€μ™€ ν…μ¤νΈλ¥Ό ν•¨κ» μ²λ¦¬ν•  μ μλ” Vision-Language λ¨λΈ

### 2. **μ„ νƒμ  νλΌλ―Έν„° ν›λ ¨**
```python
def set_model(model_args, model):
    # Vision Encoder, MLP, LLM κ°κ°μ„ λ…λ¦½μ μΌλ΅ ν™μ„±ν™”/λΉ„ν™μ„±ν™” κ°€λ¥
    - tune_mm_vision: Vision Encoder νλΌλ―Έν„° ν›λ ¨ μ—¬λ¶€
    - tune_mm_mlp: MLP λ μ΄μ–΄ νλΌλ―Έν„° ν›λ ¨ μ—¬λ¶€  
    - tune_mm_llm: LLM νλΌλ―Έν„° ν›λ ¨ μ—¬λ¶€
```

### 3. **DeepSpeed νΈν™μ„±**
- **λ¶„μ‚° ν›λ ¨** μ§€μ›
- **λ©”λ¨λ¦¬ μµμ ν™”**λ¥Ό μ„ν• DeepSpeed μ—”μ§„ μ‚¬μ©
- `UnfreezeAfterDeepSpeed` μ½λ°±μΌλ΅ DeepSpeed μ΄κΈ°ν™” ν›„ νλΌλ―Έν„° μ¬ν™μ„±ν™”

### 4. **μ»¤μ¤ν…€ μ½λ°±**
- **`PrintLossCallback`**: ν›λ ¨ μ¤‘ μ†μ‹¤κ°’κ³Ό μμΈ΅ μƒν” μ¶λ ¥
- **`UnfreezeAfterDeepSpeed`**: DeepSpeed ν™κ²½μ—μ„ Vision Encoder νλΌλ―Έν„° μ¬ν™μ„±ν™”

### 5. **λ°μ΄ν„° μ²λ¦¬**
- **μΌλ° λ°μ΄ν„° λ¨λ“**: `make_supervised_data_module`
- **ν¨ν‚Ή λ°μ΄ν„° λ¨λ“**: `make_supervised_data_module_packed` (λ©”λ¨λ¦¬ ν¨μ¨μ„±)
- μ΄λ―Έμ§€ ν¬κΈ°: 672x672 ν”½μ…€λ΅ κ³ μ •

## οΏ½οΏ½ **μ£Όμ” μ„¤μ •**

### μ΄λ―Έμ§€ μ²λ¦¬ μ„¤μ •
```python
min_pixels=451584, max_pixels=451584
resized_height=672, resized_width=672
```

### λ¨λΈ λ΅λ”© μµμ…
- `torch_dtype=torch.bfloat16`: λ©”λ¨λ¦¬ μ μ•½
- `low_cpu_mem_usage=False`: λ¶„μ‚° ν™κ²½ νΈν™μ„±
- `trust_remote_code=True`: μ»¤μ¤ν…€ μ½”λ“ ν—μ©

## οΏ½οΏ½ **λ¨λ‹ν„°λ§ κΈ°λ¥**

1. **μ‹¤μ‹κ°„ λ΅κ·Έ**: μ†μ‹¤κ°’, κ·Έλλ””μ–ΈνΈ λ…Έλ¦„, ν•™μµλ¥ , μ²λ¦¬ μ†λ„
2. **μμΈ΅ μƒν”**: 100 μ¤ν…λ§λ‹¤ μ‹¤μ  μμΈ΅ κ²°κ³Ό μ¶λ ¥
3. **νλΌλ―Έν„° μƒνƒ**: ν›λ ¨ κ°€λ¥ν• νλΌλ―Έν„° κ°μ μ¶”μ 

## οΏ½οΏ½ **μ‚¬μ© λ©μ **

μ΄ μ¤ν¬λ¦½νΈλ” **λ©€ν‹°λ¨λ‹¬ AI λ¨λΈμ„ νΉμ • νƒμ¤ν¬μ— λ§κ² νμΈνλ‹**ν•λ” λ° μ‚¬μ©λ©λ‹λ‹¤. μλ¥Ό λ“¤μ–΄:
- μ΄λ―Έμ§€ μΊ΅μ…”λ‹
- μ‹κ°μ  μ§μμ‘λ‹µ
- μ΄λ―Έμ§€ κΈ°λ° λ€ν™”
- νΉμ • λ„λ©”μΈμ μ΄λ―Έμ§€-ν…μ¤νΈ μ΄ν•΄

νΉν **λ¶€λ¶„μ  νλΌλ―Έν„° ν›λ ¨**μ„ ν†µν•΄ λ©”λ¨λ¦¬ ν¨μ¨μ„±μ„ λ†’μ΄κ³ , **DeepSpeed**λ¥Ό ν†µν• λ€κ·λ¨ λ¨λΈ ν›λ ¨μ„ μ§€μ›ν•λ” κ²ƒμ΄ νΉμ§•μ…λ‹λ‹¤.

---

_**User**_

@trainer.py μ΄κ±°λ” λ­ν•λ” μ¤ν¬λ¦½νΈμ•Ό?

---

_**Assistant**_

`trainer.py` νμΌμ„ λ¶„μ„ν•΄λ³΄κ² μµλ‹λ‹¤. μ΄ νμΌμ€ **Qwen λ©€ν‹°λ¨λ‹¬ λ¨λΈμ ν›λ ¨μ„ μ„ν• μ»¤μ¤ν…€ Trainer ν™•μ¥** μ¤ν¬λ¦½νΈμ…λ‹λ‹¤.

## π― **μ£Όμ” κΈ°λ¥**

### 1. **Flash Attention μ§€μ›** (μ£Όμ„ μ²λ¦¬λ¨)
```python
# def _flash_attention_forward(...):
#     """Flash Attentionμ„ μ‚¬μ©ν• κ³ μ† μ–΄ν…μ… κ³„μ‚°"""
#     # λ©”λ¨λ¦¬ ν¨μ¨μ μΈ μ–΄ν…μ… κµ¬ν„
```
- ν„μ¬λ” μ£Όμ„ μ²λ¦¬λμ–΄ μμ§€λ§, Flash Attentionμ„ ν†µν• λ©”λ¨λ¦¬ μµμ ν™” κΈ°λ¥ μ κ³µ
- λ€μ©λ‰ λ¨λΈ ν›λ ¨ μ‹ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ κ°μ†

### 2. **νλΌλ―Έν„° ν›λ ¨ μƒνƒ λ¨λ‹ν„°λ§**
```python
def print_trainable_parameters_visual(self):
    """Vision λ¨λ“μ ν›λ ¨ κ°€λ¥ν• νλΌλ―Έν„° μƒνƒ μ¶λ ¥"""
    # Vision Encoderμ κ° λΈ”λ΅λ³„ ν›λ ¨ μƒνƒ ν™•μΈ
    # Merger λ¨λ“ ν›λ ¨ μƒνƒ ν™•μΈ

def print_trainable_parameters(self):
    """LLM λ¨λ“μ ν›λ ¨ κ°€λ¥ν• νλΌλ―Έν„° μƒνƒ μ¶λ ¥"""
    # μ„λ² λ”©, λ μ΄μ–΄, μ •κ·ν™” λ μ΄μ–΄λ³„ ν›λ ¨ μƒνƒ ν™•μΈ
```

### 3. **κ³ κΈ‰ μµν‹°λ§μ΄μ € μ„¤μ •**
```python
def create_optimizer(self):
    """λ‹¤μ–‘ν• ν•™μµλ¥ μ„ κ°€μ§„ νλΌλ―Έν„° κ·Έλ£Ή μƒμ„±"""
```

#### **νλΌλ―Έν„° κ·Έλ£Ή λ¶„λ¥:**
1. **μΌλ° νλΌλ―Έν„°**: κΈ°λ³Έ ν•™μµλ¥  + weight decay
2. **Vision Tower νλΌλ―Έν„°**: `vision_tower_lr` + weight decay
3. **MM Projector νλΌλ―Έν„°**: `mm_projector_lr` + weight decay
4. **Bias νλΌλ―Έν„°**: κΈ°λ³Έ ν•™μµλ¥  + weight decay μ—†μ

### 4. **Monkey Patching**
```python
# κΈ°μ΅΄ ν΄λμ¤μ— μƒλ΅μ΄ λ©”μ„λ“ μ¶”κ°€
Trainer.create_optimizer = create_optimizer
Qwen2VisionTransformerPretrainedModel.print_trainable_parameters = print_trainable_parameters_visual
Qwen2VLModel.print_trainable_parameters = print_trainable_parameters
```

## οΏ½οΏ½ **ν•µμ‹¬ νΉμ§•**

### **λ‹¤μ¤‘ ν•™μµλ¥  μ§€μ›**
- **Vision Encoder**: `vision_tower_lr`λ΅ λ³„λ„ ν•™μµλ¥  μ„¤μ • κ°€λ¥
- **MM Projector (Merger)**: `mm_projector_lr`λ΅ λ³„λ„ ν•™μµλ¥  μ„¤μ • κ°€λ¥
- **LLM νλΌλ―Έν„°**: κΈ°λ³Έ ν•™μµλ¥  μ‚¬μ©

### **Weight Decay λ¶„λ¦¬**
- **LayerNorm/RMSNorm νλΌλ―Έν„°**: weight decay μ μ©
- **Bias νλΌλ―Έν„°**: weight decay μ μ™Έ
- **μΌλ° κ°€μ¤‘μΉ**: weight decay μ μ©

### **ν›λ ¨ μƒνƒ μ¶”μ **
- Vision λ¨λ“μ κ° μ–΄ν…μ… λΈ”λ΅λ³„ ν›λ ¨ μƒνƒ ν™•μΈ
- LLM λ¨λ“μ κ° λ μ΄μ–΄λ³„ ν›λ ¨ μƒνƒ ν™•μΈ
- Merger λ¨λ“ ν›λ ¨ μƒνƒ ν™•μΈ

## οΏ½οΏ½ **μ‚¬μ© λ©μ **

μ΄ μ¤ν¬λ¦½νΈλ” **λ©€ν‹°λ¨λ‹¬ λ¨λΈμ ν¨μ¨μ μΈ νμΈνλ‹**μ„ μ„ν•΄ λ‹¤μκ³Ό κ°™μ€ κΈ°λ¥μ„ μ κ³µν•©λ‹λ‹¤:

1. **λ©”λ¨λ¦¬ μµμ ν™”**: Flash Attentionμ„ ν†µν• λ©”λ¨λ¦¬ μ‚¬μ©λ‰ κ°μ†
2. **μ μ—°ν• ν•™μµλ¥ **: λ¨λ“λ³„λ΅ λ‹¤λ¥Έ ν•™μµλ¥  μ μ© κ°€λ¥
3. **μƒμ„Έν• λ¨λ‹ν„°λ§**: μ–΄λ–¤ νλΌλ―Έν„°κ°€ μ‹¤μ λ΅ ν›λ ¨λκ³  μλ”μ§€ ν™•μΈ
4. **μ•μ •μ μΈ ν›λ ¨**: μ μ ν• weight decay μ„¤μ •μΌλ΅ κ³Όμ ν•© λ°©μ§€

## π”— **train_qwen.pyμ™€μ κ΄€κ³„**

- `train_qwen.py`μ—μ„ μ΄ `trainer.py`μ κΈ°λ¥λ“¤μ„ ν™μ©
- νΉν `UnfreezeAfterDeepSpeed` μ½λ°±κ³Ό ν•¨κ» μ‚¬μ©ν•μ—¬ DeepSpeed ν™κ²½μ—μ„ μ•μ •μ μΈ ν›λ ¨ μ§€μ›
- λ©€ν‹°λ¨λ‹¬ λ¨λΈμ λ³µμ΅ν• κµ¬μ΅°λ¥Ό ν¨μ¨μ μΌλ΅ ν›λ ¨ν•  μ μλ„λ΅ λ„μ™€μ£Όλ” ν•µμ‹¬ λ„κµ¬

μ΄ μ¤ν¬λ¦½νΈλ” **λ€κ·λ¨ λ©€ν‹°λ¨λ‹¬ λ¨λΈ ν›λ ¨μ λ³µμ΅μ„±μ„ κ΄€λ¦¬**ν•κ³  **ν¨μ¨μ μΈ νμΈνλ‹**μ„ κ°€λ¥ν•κ² ν•λ” μ¤‘μ”ν• μ—­ν• μ„ ν•©λ‹λ‹¤.

---

_**User**_

@data_qwen.py μ΄κ±°λ” λ­ν•λ” μ½”λ“μ•Ό?

---

_**Assistant**_

`data_qwen.py` νμΌμ„ λ¶„μ„ν•΄λ³΄κ² μµλ‹λ‹¤. μ΄ νμΌμ€ **Qwen λ©€ν‹°λ¨λ‹¬ λ¨λΈμ„ μ„ν• λ°μ΄ν„° μ²λ¦¬ λ° μ „μ²λ¦¬ μ¤ν¬λ¦½νΈ**μ…λ‹λ‹¤.

## π― **μ£Όμ” κΈ°λ¥**

### 1. **λ©€ν‹°λ¨λ‹¬ λ°μ΄ν„° μ²λ¦¬**
```python
# μ΄λ―Έμ§€μ™€ λΉ„λ””μ¤ λ¨λ‘ μ§€μ›
DEFAULT_IMAGE_TOKEN = "<image>"
DEFAULT_VIDEO_TOKEN = "<video>"
IMAGE_TOKEN_INDEX = 151655
VIDEO_TOKEN_INDEX = 151656
```

### 2. **λ€ν™”ν• λ°μ΄ν„° μ „μ²λ¦¬**
```python
def preprocess_qwen_2_visual(sources, tokenizer, grid_thw_image, grid_thw_video):
    """λ€ν™”ν• λ°μ΄ν„°λ¥Ό λ¨λΈ μ…λ ¥ ν•μ‹μΌλ΅ λ³€ν™"""
    # μ‹μ¤ν… λ©”μ‹μ§€ μ¶”κ°€
    # μ΄λ―Έμ§€/λΉ„λ””μ¤ ν† ν° μ²λ¦¬
    # μ±„ν… ν…ν”λ¦Ώ μ μ©
```

### 3. **LazySupervisedDataset ν΄λμ¤**
```python
class LazySupervisedDataset(Dataset):
    """μ§€μ—° λ΅λ”© λ°©μ‹μ μ§€λ„ν•™μµ λ°μ΄ν„°μ…‹"""
```

#### **μ£Όμ” νΉμ§•:**
- **μ§€μ—° λ΅λ”©**: λ©”λ¨λ¦¬ ν¨μ¨μ„±μ„ μ„ν•΄ ν•„μ”ν•  λ•λ§ λ°μ΄ν„° λ΅λ“
- **λ©€ν‹°λ¨λ‹¬ μ§€μ›**: μ΄λ―Έμ§€, λΉ„λ””μ¤, ν…μ¤νΈ λ™μ‹ μ²λ¦¬
- **μ—λ¬ λ³µκµ¬**: νμΌ μ†μƒ μ‹ λ‹¤λ¥Έ μƒν”λ΅ λ€μ²΄
- **μƒν”λ§ μ§€μ›**: λ°μ΄ν„°μ…‹λ³„ μƒν”λ§ λΉ„μ¨ μ„¤μ • κ°€λ¥

### 4. **μ΄λ―Έμ§€ μ²λ¦¬**
```python
def process_image_unified(self, image_file):
    """μ΄λ―Έμ§€ μ „μ²λ¦¬ λ° ν¨μΉν™”"""
    # PILλ΅ μ΄λ―Έμ§€ λ΅λ“
    # μ΄λ―Έμ§€ ν”„λ΅μ„Έμ„λ΅ μ „μ²λ¦¬
    # ν¨μΉ ν¬κΈ° λ° κ·Έλ¦¬λ“ μ •λ³΄ λ°ν™
```

### 5. **λΉ„λ””μ¤ μ²λ¦¬**
```python
def process_video(self, video_file):
    """λΉ„λ””μ¤ ν”„λ μ„ μ¶”μ¶ λ° μ²λ¦¬"""
    # Decordλ¥Ό μ‚¬μ©ν• λΉ„λ””μ¤ λ΅λ”©
    # ν”„λ μ„ μƒν”λ§ (4-8ν”„λ μ„)
    # μ‹κ°„ κ°„κ²© κΈ°λ° ν”„λ μ„ μ„ νƒ
```

### 6. **λ°μ΄ν„° μ½λ μ΄ν„°**
```python
@dataclass
class DataCollatorForSupervisedDataset:
    """λ°°μΉ μƒμ„±μ„ μ„ν• λ°μ΄ν„° μ½λ μ΄ν„°"""
    # μ‹ν€€μ¤ ν¨λ”©
    # λ©€ν‹°λ¨λ‹¬ λ°μ΄ν„° κ²°ν•©
    # ν¬μ§€μ… ID μƒμ„±
```

## π”§ **ν•µμ‹¬ μ²λ¦¬ κ³Όμ •**

### **1. λ°μ΄ν„° λ΅λ”©**
```python
# JSONL λλ” JSON ν•μ‹μ μ–΄λ…Έν…μ΄μ… νμΌ μ½κΈ°
# μƒν”λ§ λΉ„μ¨ μ μ©
# λ°μ΄ν„° κ²½λ΅ μ„¤μ •
```

### **2. λ©€ν‹°λ¨λ‹¬ ν† ν°ν™”**
```python
# <image> ν† ν°μ„ <|vision_start|> + ν¨λ“ + <|vision_end|>λ΅ λ³€ν™
# <video> ν† ν°μ„ λΉ„λ””μ¤ μ „μ© ν† ν°μΌλ΅ λ³€ν™
# μ±„ν… ν…ν”λ¦Ώ μ μ©
```

### **3. μ‹κ°μ  λ°μ΄ν„° μ²λ¦¬**
```python
# μ΄λ―Έμ§€: 672x672 ν¬κΈ°λ΅ λ¦¬μ‚¬μ΄μ¦, ν¨μΉν™”
# λΉ„λ””μ¤: ν”„λ μ„ μ¶”μ¶, μ‹κ°„ μ •λ³΄ ν¬ν•¨
# RoPE μΈλ±μ¤ μƒμ„± (2D μ„μΉ μΈμ½”λ”©)
```

### **4. λ°°μΉ μƒμ„±**
```python
# μ‹ν€€μ¤ κΈΈμ΄ λ§μ¶¤ (ν¨λ”©)
# λ©€ν‹°λ¨λ‹¬ λ°μ΄ν„° κ²°ν•©
# μ–΄ν…μ… λ§μ¤ν¬ μƒμ„±
```

## π“ **μ§€μ›ν•λ” λ°μ΄ν„° ν•μ‹**

### **μ…λ ¥ λ°μ΄ν„° κµ¬μ΅°:**
```json
{
  "conversations": [
    {"from": "human", "value": "μ΄ μ΄λ―Έμ§€λ¥Ό μ„¤λ…ν•΄μ£Όμ„Έμ” <image>"},
    {"from": "gpt", "value": "μ΄ μ΄λ―Έμ§€λ”..."}
  ],
  "image": "path/to/image.jpg",
  "data_path": "/data/images/"
}
```

### **μ²λ¦¬λ μ¶λ ¥:**
```python
{
  "input_ids": tensor(...),      # ν† ν°ν™”λ μ…λ ¥
  "labels": tensor(...),         # ν•™μµ λ μ΄λΈ”
  "pixel_values": tensor(...),   # μ΄λ―Έμ§€ ν¨μΉ
  "position_ids": tensor(...),   # 2D μ„μΉ μΈμ½”λ”©
  "attention_mask": tensor(...)  # μ–΄ν…μ… λ§μ¤ν¬
}
```

## π― **μ£Όμ” μ„¤μ • μµμ…**

### **μ΄λ―Έμ§€ μ„¤μ •:**
- `max_pixels`: 451584 (672x672)
- `min_pixels`: 451584
- ν¨μΉ ν¬κΈ°: 14x14

### **λΉ„λ””μ¤ μ„¤μ •:**
- `video_min_frames`: 4
- `video_max_frames`: 8
- `base_interval`: 4μ΄ κ°„κ²©

### **λ°μ΄ν„° μ²λ¦¬:**
- `data_flatten`: μ‹ν€€μ¤ ν¨ν‚Ή μ—¬λ¶€
- `sampling_rate`: λ°μ΄ν„°μ…‹λ³„ μƒν”λ§ λΉ„μ¨

## π”— **train_qwen.pyμ™€μ κ΄€κ³„**

- `train_qwen.py`μ—μ„ `make_supervised_data_module()` ν•¨μ νΈμ¶
- λ©€ν‹°λ¨λ‹¬ λ°μ΄ν„°λ¥Ό λ¨λΈμ΄ μ΄ν•΄ν•  μ μλ” ν•μ‹μΌλ΅ λ³€ν™
- ν¨μ¨μ μΈ λ°°μΉ μƒμ„±μ„ ν†µν•΄ ν›λ ¨ μ†λ„ ν–¥μƒ

μ΄ μ¤ν¬λ¦½νΈλ” **λ³µμ΅ν• λ©€ν‹°λ¨λ‹¬ λ°μ΄ν„°λ¥Ό μ²΄κ³„μ μΌλ΅ μ²λ¦¬**ν•κ³  **λ€ν™”ν• AI λ¨λΈ ν›λ ¨μ— μµμ ν™”λ λ°μ΄ν„° νμ΄ν”„λΌμΈ**μ„ μ κ³µν•λ” ν•µμ‹¬ μ—­ν• μ„ ν•©λ‹λ‹¤.

---

